\section{Conclusion}
This work explored the application of \textbf{clustering algorithms}—\textbf{K-Means}, \textbf{Global K-Means}, \textbf{X-Means} \textbf{Optics}, \textbf{Spectral Clustering}, and \textbf{Fuzzy C-Means}—across diverse datasets: \textbf{Hepatitis}, \textbf{Mushroom}, and \textbf{Pen-based}. The study revealed that clustering performance depends strongly on the \textbf{algorithm choice}, \textbf{hyperparameter configurations}, and \textbf{dataset characteristics}. 

Through this process, we learned that:
\begin{itemize}
	\item The \textbf{nature of the data} (e.g., density, dimensionality, and class distribution) significantly influences clustering quality and appropriate parameter selection.
	\item Careful \textbf{evaluation using multiple metrics} (ARI, NMI, DBI, Silhouette, and CHS) provides a more balanced view of algorithm performance, avoiding over-reliance on any single measure.
	\item Dimensionality reduction techniques, such as \textbf{PCA} and \textbf{UMAP}, play a crucial role not only in visualization but also in understanding \textbf{hidden structures} within the data.
	\item Robust clustering outcomes often require a \textbf{systematic approach to hyperparameter tuning}, tailored to the dataset's specific properties.
\end{itemize}

The main lesson learned is that no single clustering method is universally optimal. Instead, the choice of method and configuration must be \textbf{data-driven} and guided by domain knowledge. Future work could explore integrating clustering algorithms with ensemble methods or hybrid approaches to further enhance performance across complex datasets.

In summary, this study highlights the importance of \textbf{methodological rigor} and \textbf{data-aware experimentation} when applying clustering techniques. The lessons learned can provide practical guidelines for adapting these methods to real-world problems.