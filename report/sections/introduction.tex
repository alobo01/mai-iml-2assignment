\section{Introduction}
\textbf{Clustering algorithms} aim to uncover natural groupings in unlabeled data, but their \textbf{effectiveness} depends on the \textbf{choice of algorithm}, \textbf{hyperparameters}, and \textbf{data characteristics}. This work systematically compares \textbf{K-Means}, its \textbf{variations Global K-Means and X-Means}, \textbf{Optics} (a \textbf{density-based ordering method}), \textbf{Spectral Clustering} (a \textbf{graph-based partitioning method}), and \textbf{Fuzzy C-Means (FCM)} (based on \textbf{fuzzy sets}) on three diverse datasets: \textbf{Hepatitis}, \textbf{Mushroom}, and \textbf{Pen-based}.

We evaluate clustering performance using multiple metrics, including \textbf{ARI}, \textbf{NMI}, \textbf{DBI}, \textbf{Silhouette}, and \textbf{CHS scores}. Dimensionality reduction methods, such as \textbf{PCA} and \textbf{UMAP}, are applied to visualize high-dimensional datasets effectively.

Our analysis identifies key trends in algorithm behavior, such as the \textbf{stability of Global K-Means}, the \textbf{adaptability of FCM} to varying densities, the \textbf{flexibility of X-Means} in determining the number of clusters, and the \textbf{sensitivity of Optics and Spectral Clustering} to complex data structures. These insights guide the \textbf{selection of clustering methods} tailored to specific datasets and objectives.